{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"MLE@Samsung_Research_v2.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uSh43HodxbNh"},"source":["# Today you are a MLE@Samsung Research and your goal is to perform segmentation of cystic regions from OCT images.\n","## This work is based on the recent publication https://arxiv.org/abs/2008.02952\n","## This model is adapted from the original codebase in https://github.com/sohiniroych/U-net_using_TF2"]},{"cell_type":"markdown","metadata":{"id":"OJDGFKOMxbNq"},"source":["# Optical Coherence Tomography (OCT) images represent grayscale images representing the depth of retina. Cystic regions are gaps in the retina as shown below\n","![image.png](attachment:image.png)\n","\n","## Yor goal is to segment the cysts (dark gaps) in the images using the U-net model."]},{"cell_type":"markdown","metadata":{"id":"5FbrnMPkxbNr"},"source":["# Your Deliverables are as follows:\n","### 1. Train a u-net model from scratch and test performance on test images for 2 OCT repos.\n","### 2. Vary the loss function, kernel dialation, depthwise separable kernels and report results.\n","### 3. Report observations with and without Batch normalization and Dropout at test time.\n","### 4. If you use Dropout at test time and generate 2-3 test predictions, what do you observe from these predictions? "]},{"cell_type":"markdown","metadata":{"id":"Aky_YKeAxbNs"},"source":["# Task 1: Implement U-net model from scratch for the 'cirrus_3' data set. Report performance on test set and save the model as 'unet_cirrus.hdf5'\n","## [Instructor Led]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYaJTsVXyw6h","executionInfo":{"status":"ok","timestamp":1607808851292,"user_tz":300,"elapsed":17079,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"be3ed1d6-771c-48a7-8629-a6c64b45c309"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ccH8sSBxbNs","executionInfo":{"status":"ok","timestamp":1607808861799,"user_tz":300,"elapsed":6889,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["#This code snippet helps if your computer has RTX 2070 GPU. If not then comment this cell.\n","from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eUvYHoL4xbNs"},"source":["## Lets start by stepwise defining all libraries and functions needed to generate the model and pre-process the data"]},{"cell_type":"code","metadata":{"id":"6lAdxWtBxbNt","executionInfo":{"status":"ok","timestamp":1607808865102,"user_tz":300,"elapsed":1096,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["#Step 1: Load libraries for the U-net Model\n","import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras import backend as keras\n","#from tensorflow import keras\n","import tensorflow as tf"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"SRlHVXzwxbNt","executionInfo":{"status":"ok","timestamp":1607808865103,"user_tz":300,"elapsed":550,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import skimage.io as io\n","import skimage.transform as trans\n","import matplotlib.pyplot as plt\n","import scipy.misc as sc"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPjuWGfYxbNu","executionInfo":{"status":"ok","timestamp":1607808865388,"user_tz":300,"elapsed":440,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["#Define Additional loss functions for Task 2\n","def dice_coef(y_true, y_pred, smooth=1):\n","    intersection = keras.sum(y_true * y_pred, axis=[1,2,3])\n","    union = keras.sum(y_true, axis=[1,2,3]) + keras.sum(y_pred, axis=[1,2,3])\n","    return keras.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdIi2qBZxbNu","executionInfo":{"status":"ok","timestamp":1607813578040,"user_tz":300,"elapsed":328,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["#Step 2: Define the U-net model\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = tf.keras.Input(shape=input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n","    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n","    conv1 = BatchNormalization()(conv1)\n","    #[Try removing BatchNormalization and see performance]\n","    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    \n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    \n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    \n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","   \n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = 'accuracy')\n","    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n","    \n","\n","    if(pretrained_weights):\n","    \tmodel=keras.models.load_model(pretrained_weights)\n","\n","    return model"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9QMDA9rCiZx","executionInfo":{"status":"ok","timestamp":1607813591217,"user_tz":300,"elapsed":357,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["# Redefinition for 5x5 kernels\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = tf.keras.Input(shape=input_size)\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n","    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n","    conv1 = BatchNormalization()(conv1)\n","    #[Try removing BatchNormalization and see performance]\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    \n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    \n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    \n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","   \n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-5), loss = dice_coef_loss, metrics = ['accuracy', dice_coef])\n","    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n","    \n","\n","    if(pretrained_weights):\n","    \tmodel=keras.models.load_model(pretrained_weights)\n","\n","    return model"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKamHr5i7Yo9","executionInfo":{"status":"ok","timestamp":1607814807655,"user_tz":300,"elapsed":342,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["# Redefinition for 5x5 kernels with depthwise convolutions\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = tf.keras.Input(shape=input_size)\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n","    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n","    conv1 = BatchNormalization()(conv1)\n","    #[Try removing BatchNormalization and see performance]\n","    conv1 = DepthwiseConv2D(3, padding = 'same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = DepthwiseConv2D(3, padding = 'same')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    \n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    \n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    \n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","   \n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-5), loss = dice_coef_loss, metrics = ['accuracy', dice_coef])\n","    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n","    \n","\n","    if(pretrained_weights):\n","    \tmodel=keras.models.load_model(pretrained_weights)\n","\n","    return model"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWw53G9CZb3n","executionInfo":{"status":"ok","timestamp":1607817701947,"user_tz":300,"elapsed":324,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["# Redefinition for 5x5 kernels, no batch norm in decoder\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = tf.keras.Input(shape=input_size)\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n","    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n","    conv1 = BatchNormalization()(conv1)\n","    #[Try removing BatchNormalization and see performance]\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    #conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    #conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    \n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    \n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    \n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","   \n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-5), loss = dice_coef_loss, metrics = ['accuracy', dice_coef])\n","    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n","    \n","\n","    if(pretrained_weights):\n","    \tmodel=keras.models.load_model(pretrained_weights)\n","\n","    return model"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"q3oIRv_GbmSR","executionInfo":{"status":"ok","timestamp":1607818646863,"user_tz":300,"elapsed":496,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["# Redefinition for 5x5 kernels, extra batch norm in decoder\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = tf.keras.Input(shape=input_size)\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n","    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n","    conv1 = BatchNormalization()(conv1)\n","    #[Try removing BatchNormalization and see performance]\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","   \n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-5), loss = dice_coef_loss, metrics = ['accuracy', dice_coef])\n","    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n","    \n","\n","    if(pretrained_weights):\n","    \tmodel=keras.models.load_model(pretrained_weights)\n","\n","    return model"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"WiqjyNCvg25o","executionInfo":{"status":"ok","timestamp":1607819644455,"user_tz":300,"elapsed":330,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["# Redefinition for 5x5 kernels, training=True in dropout layers\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = tf.keras.Input(shape=input_size)\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n","    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n","    conv1 = BatchNormalization()(conv1)\n","    #[Try removing BatchNormalization and see performance]\n","    conv1 = Conv2D(64, 5, dilation_rate=2, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4, training=True)#training=True will enable dropout for test data\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5, training=True)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    \n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    \n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    \n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","   \n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-5), loss = dice_coef_loss, metrics = ['accuracy', dice_coef])\n","    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n","    \n","\n","    if(pretrained_weights):\n","    \tmodel=keras.models.load_model(pretrained_weights)\n","\n","    return model"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"id":"AU50D7sexbNv","executionInfo":{"status":"ok","timestamp":1607808867676,"user_tz":300,"elapsed":1727,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["#All additional functions for data prep and evaluation are housed in unet_helper_finctions.py\n","#from unet_helper_functions import *\n","import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/Week 7')\n","from unet_helper_functions import *"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-rJin-Z9xbNv"},"source":["## All definitions are now done! Lets start using the functions now...\n","## B. Call to image data generator, model initialization, followed by model fitting."]},{"cell_type":"code","metadata":{"id":"Zz0X5SbWxbNv","executionInfo":{"status":"ok","timestamp":1607819651899,"user_tz":300,"elapsed":412,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["#Step 1: Call to image data generator in keras\n","data_gen_args = dict(rotation_range=0.2,\n","                    width_shift_range=0.05,\n","                    height_shift_range=0.05,\n","                    shear_range=0.05,\n","                    zoom_range=[0.7,1],\n","                    horizontal_flip=True,\n","                    fill_mode='nearest')\n","PATH='./Data/cirrus_3/train/'"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IK1t4hYxbNw","executionInfo":{"status":"ok","timestamp":1607819652222,"user_tz":300,"elapsed":409,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["if not os.path.exists(PATH+'aug'):\n","    os.makedirs(PATH+'aug')\n","    \n","if not os.path.exists('./Data/cirrus_3/test/'+'pred'):\n","    os.makedirs('./Data/cirrus_3/test/'+'pred')    \n","data_gen = trainGenerator(10,PATH,'Image','GT',data_gen_args, save_to_dir = PATH+'aug')"],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqY-mevwxbNw","executionInfo":{"status":"ok","timestamp":1607819652991,"user_tz":300,"elapsed":853,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"65e2d11b-d48e-4888-ec6f-47c2d752f478"},"source":["#Step 2: Initialize the model. Train from scratch!\n","model = unet()\n","model.summary()"],"execution_count":100,"outputs":[{"output_type":"stream","text":["Model: \"functional_31\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_17 (InputLayer)           [(None, 256, 256, 1) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_349 (Conv2D)             (None, 256, 256, 64) 1664        input_17[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_160 (BatchN (None, 256, 256, 64) 256         conv2d_349[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_350 (Conv2D)             (None, 256, 256, 64) 102464      batch_normalization_160[0][0]    \n","__________________________________________________________________________________________________\n","batch_normalization_161 (BatchN (None, 256, 256, 64) 256         conv2d_350[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_63 (MaxPooling2D) (None, 128, 128, 64) 0           batch_normalization_161[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_351 (Conv2D)             (None, 128, 128, 128 73856       max_pooling2d_63[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_162 (BatchN (None, 128, 128, 128 512         conv2d_351[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_352 (Conv2D)             (None, 128, 128, 128 147584      batch_normalization_162[0][0]    \n","__________________________________________________________________________________________________\n","batch_normalization_163 (BatchN (None, 128, 128, 128 512         conv2d_352[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_64 (MaxPooling2D) (None, 64, 64, 128)  0           batch_normalization_163[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_353 (Conv2D)             (None, 64, 64, 256)  295168      max_pooling2d_64[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_164 (BatchN (None, 64, 64, 256)  1024        conv2d_353[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_354 (Conv2D)             (None, 64, 64, 256)  590080      batch_normalization_164[0][0]    \n","__________________________________________________________________________________________________\n","batch_normalization_165 (BatchN (None, 64, 64, 256)  1024        conv2d_354[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_65 (MaxPooling2D) (None, 32, 32, 256)  0           batch_normalization_165[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_355 (Conv2D)             (None, 32, 32, 512)  1180160     max_pooling2d_65[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_166 (BatchN (None, 32, 32, 512)  2048        conv2d_355[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_356 (Conv2D)             (None, 32, 32, 512)  2359808     batch_normalization_166[0][0]    \n","__________________________________________________________________________________________________\n","batch_normalization_167 (BatchN (None, 32, 32, 512)  2048        conv2d_356[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_30 (Dropout)            (None, 32, 32, 512)  0           batch_normalization_167[0][0]    \n","__________________________________________________________________________________________________\n","max_pooling2d_66 (MaxPooling2D) (None, 16, 16, 512)  0           dropout_30[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_357 (Conv2D)             (None, 16, 16, 1024) 4719616     max_pooling2d_66[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_168 (BatchN (None, 16, 16, 1024) 4096        conv2d_357[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_358 (Conv2D)             (None, 16, 16, 1024) 9438208     batch_normalization_168[0][0]    \n","__________________________________________________________________________________________________\n","batch_normalization_169 (BatchN (None, 16, 16, 1024) 4096        conv2d_358[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 16, 16, 1024) 0           batch_normalization_169[0][0]    \n","__________________________________________________________________________________________________\n","up_sampling2d_60 (UpSampling2D) (None, 32, 32, 1024) 0           dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_359 (Conv2D)             (None, 32, 32, 512)  2097664     up_sampling2d_60[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_60 (Concatenate)    (None, 32, 32, 1024) 0           dropout_30[0][0]                 \n","                                                                 conv2d_359[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_360 (Conv2D)             (None, 32, 32, 512)  4719104     concatenate_60[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_361 (Conv2D)             (None, 32, 32, 512)  2359808     conv2d_360[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_61 (UpSampling2D) (None, 64, 64, 512)  0           conv2d_361[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_362 (Conv2D)             (None, 64, 64, 256)  524544      up_sampling2d_61[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_61 (Concatenate)    (None, 64, 64, 512)  0           batch_normalization_165[0][0]    \n","                                                                 conv2d_362[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_363 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_61[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_364 (Conv2D)             (None, 64, 64, 256)  590080      conv2d_363[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_62 (UpSampling2D) (None, 128, 128, 256 0           conv2d_364[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_365 (Conv2D)             (None, 128, 128, 128 131200      up_sampling2d_62[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_62 (Concatenate)    (None, 128, 128, 256 0           batch_normalization_163[0][0]    \n","                                                                 conv2d_365[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_366 (Conv2D)             (None, 128, 128, 128 295040      concatenate_62[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_367 (Conv2D)             (None, 128, 128, 128 147584      conv2d_366[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_63 (UpSampling2D) (None, 256, 256, 128 0           conv2d_367[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_368 (Conv2D)             (None, 256, 256, 64) 32832       up_sampling2d_63[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_63 (Concatenate)    (None, 256, 256, 128 0           batch_normalization_161[0][0]    \n","                                                                 conv2d_368[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_369 (Conv2D)             (None, 256, 256, 64) 73792       concatenate_63[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_370 (Conv2D)             (None, 256, 256, 64) 36928       conv2d_369[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_371 (Conv2D)             (None, 256, 256, 2)  1154        conv2d_370[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_372 (Conv2D)             (None, 256, 256, 1)  3           conv2d_371[0][0]                 \n","==================================================================================================\n","Total params: 31,114,117\n","Trainable params: 31,106,181\n","Non-trainable params: 7,936\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IHMpX_m6xbNx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607819693852,"user_tz":300,"elapsed":304,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"f02fbae0-b37b-44cf-f82d-fc4f239b8591"},"source":["#Step 3: Initialize Tensorboard to monitor changes in Model Loss \n","import datetime\n","%load_ext tensorboard\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"],"execution_count":101,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ets4J5a9xbNy","executionInfo":{"status":"ok","timestamp":1607820426459,"user_tz":300,"elapsed":732468,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"789da1fd-c4af-4c80-8311-3234b92070fc"},"source":["#Step 4: Fit the u-net model\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_cirrus.hdf5', monitor='loss',verbose=1, save_best_only=True)\n","model.fit(data_gen,steps_per_epoch=15,epochs=50,verbose=1, callbacks=[model_checkpoint, tensorboard_callback])"],"execution_count":102,"outputs":[{"output_type":"stream","text":["Found 91 images belonging to 1 classes.\n","Found 91 images belonging to 1 classes.\n","Epoch 1/50\n"," 2/15 [===>..........................] - ETA: 9s - loss: -0.0729 - accuracy: 0.4601 - dice_coef: 0.0729WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2881s vs `on_train_batch_end` time: 0.6785s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2881s vs `on_train_batch_end` time: 0.6785s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["15/15 [==============================] - ETA: 0s - loss: -0.0931 - accuracy: 0.3255 - dice_coef: 0.0889\n","Epoch 00001: loss improved from inf to -0.09306, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 19s 1s/step - loss: -0.0931 - accuracy: 0.3255 - dice_coef: 0.0889\n","Epoch 2/50\n","15/15 [==============================] - ETA: 0s - loss: -0.1470 - accuracy: 0.5519 - dice_coef: 0.1550\n","Epoch 00002: loss improved from -0.09306 to -0.14696, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 987ms/step - loss: -0.1470 - accuracy: 0.5519 - dice_coef: 0.1550\n","Epoch 3/50\n","15/15 [==============================] - ETA: 0s - loss: -0.4179 - accuracy: 0.9479 - dice_coef: 0.4345\n","Epoch 00003: loss improved from -0.14696 to -0.41786, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.4179 - accuracy: 0.9479 - dice_coef: 0.4345\n","Epoch 4/50\n","15/15 [==============================] - ETA: 0s - loss: -0.5299 - accuracy: 0.9615 - dice_coef: 0.5296\n","Epoch 00004: loss improved from -0.41786 to -0.52993, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 971ms/step - loss: -0.5299 - accuracy: 0.9615 - dice_coef: 0.5296\n","Epoch 5/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6028 - accuracy: 0.9683 - dice_coef: 0.6055\n","Epoch 00005: loss improved from -0.52993 to -0.60277, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.6028 - accuracy: 0.9683 - dice_coef: 0.6055\n","Epoch 6/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6191 - accuracy: 0.9696 - dice_coef: 0.6166\n","Epoch 00006: loss improved from -0.60277 to -0.61908, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 994ms/step - loss: -0.6191 - accuracy: 0.9696 - dice_coef: 0.6166\n","Epoch 7/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6407 - accuracy: 0.9733 - dice_coef: 0.6132\n","Epoch 00007: loss improved from -0.61908 to -0.64072, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.6407 - accuracy: 0.9733 - dice_coef: 0.6132\n","Epoch 8/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6620 - accuracy: 0.9748 - dice_coef: 0.6751\n","Epoch 00008: loss improved from -0.64072 to -0.66197, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 971ms/step - loss: -0.6620 - accuracy: 0.9748 - dice_coef: 0.6751\n","Epoch 9/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6596 - accuracy: 0.9751 - dice_coef: 0.6599\n","Epoch 00009: loss did not improve from -0.66197\n","15/15 [==============================] - 13s 892ms/step - loss: -0.6596 - accuracy: 0.9751 - dice_coef: 0.6599\n","Epoch 10/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6688 - accuracy: 0.9738 - dice_coef: 0.6510\n","Epoch 00010: loss improved from -0.66197 to -0.66882, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 14s 956ms/step - loss: -0.6688 - accuracy: 0.9738 - dice_coef: 0.6510\n","Epoch 11/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6747 - accuracy: 0.9758 - dice_coef: 0.6765\n","Epoch 00011: loss improved from -0.66882 to -0.67470, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.6747 - accuracy: 0.9758 - dice_coef: 0.6765\n","Epoch 12/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6685 - accuracy: 0.9740 - dice_coef: 0.6735\n","Epoch 00012: loss did not improve from -0.67470\n","15/15 [==============================] - 13s 883ms/step - loss: -0.6685 - accuracy: 0.9740 - dice_coef: 0.6735\n","Epoch 13/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6640 - accuracy: 0.9728 - dice_coef: 0.6732\n","Epoch 00013: loss did not improve from -0.67470\n","15/15 [==============================] - 14s 905ms/step - loss: -0.6640 - accuracy: 0.9728 - dice_coef: 0.6732\n","Epoch 14/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6781 - accuracy: 0.9750 - dice_coef: 0.6759\n","Epoch 00014: loss improved from -0.67470 to -0.67813, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 969ms/step - loss: -0.6781 - accuracy: 0.9750 - dice_coef: 0.6759\n","Epoch 15/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6837 - accuracy: 0.9764 - dice_coef: 0.6918\n","Epoch 00015: loss improved from -0.67813 to -0.68366, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.6837 - accuracy: 0.9764 - dice_coef: 0.6918\n","Epoch 16/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6915 - accuracy: 0.9747 - dice_coef: 0.7006\n","Epoch 00016: loss improved from -0.68366 to -0.69154, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 988ms/step - loss: -0.6915 - accuracy: 0.9747 - dice_coef: 0.7006\n","Epoch 17/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6960 - accuracy: 0.9763 - dice_coef: 0.6811\n","Epoch 00017: loss improved from -0.69154 to -0.69596, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.6960 - accuracy: 0.9763 - dice_coef: 0.6811\n","Epoch 18/50\n","15/15 [==============================] - ETA: 0s - loss: -0.6967 - accuracy: 0.9766 - dice_coef: 0.7006\n","Epoch 00018: loss improved from -0.69596 to -0.69674, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 989ms/step - loss: -0.6967 - accuracy: 0.9766 - dice_coef: 0.7006\n","Epoch 19/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7006 - accuracy: 0.9778 - dice_coef: 0.7004\n","Epoch 00019: loss improved from -0.69674 to -0.70061, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 16s 1s/step - loss: -0.7006 - accuracy: 0.9778 - dice_coef: 0.7004\n","Epoch 20/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7118 - accuracy: 0.9765 - dice_coef: 0.7043\n","Epoch 00020: loss improved from -0.70061 to -0.71176, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 978ms/step - loss: -0.7118 - accuracy: 0.9765 - dice_coef: 0.7043\n","Epoch 21/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7020 - accuracy: 0.9768 - dice_coef: 0.7035\n","Epoch 00021: loss did not improve from -0.71176\n","15/15 [==============================] - 14s 901ms/step - loss: -0.7020 - accuracy: 0.9768 - dice_coef: 0.7035\n","Epoch 22/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7117 - accuracy: 0.9784 - dice_coef: 0.6974\n","Epoch 00022: loss did not improve from -0.71176\n","15/15 [==============================] - 13s 865ms/step - loss: -0.7117 - accuracy: 0.9784 - dice_coef: 0.6974\n","Epoch 23/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7096 - accuracy: 0.9785 - dice_coef: 0.7004\n","Epoch 00023: loss did not improve from -0.71176\n","15/15 [==============================] - 13s 893ms/step - loss: -0.7096 - accuracy: 0.9785 - dice_coef: 0.7004\n","Epoch 24/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7111 - accuracy: 0.9767 - dice_coef: 0.7025\n","Epoch 00024: loss did not improve from -0.71176\n","15/15 [==============================] - 13s 866ms/step - loss: -0.7111 - accuracy: 0.9767 - dice_coef: 0.7025\n","Epoch 25/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7180 - accuracy: 0.9787 - dice_coef: 0.7261\n","Epoch 00025: loss improved from -0.71176 to -0.71800, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.7180 - accuracy: 0.9787 - dice_coef: 0.7261\n","Epoch 26/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7117 - accuracy: 0.9767 - dice_coef: 0.7171\n","Epoch 00026: loss did not improve from -0.71800\n","15/15 [==============================] - 13s 871ms/step - loss: -0.7117 - accuracy: 0.9767 - dice_coef: 0.7171\n","Epoch 27/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7183 - accuracy: 0.9794 - dice_coef: 0.7253\n","Epoch 00027: loss improved from -0.71800 to -0.71834, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.7183 - accuracy: 0.9794 - dice_coef: 0.7253\n","Epoch 28/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7194 - accuracy: 0.9766 - dice_coef: 0.7125\n","Epoch 00028: loss improved from -0.71834 to -0.71945, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 981ms/step - loss: -0.7194 - accuracy: 0.9766 - dice_coef: 0.7125\n","Epoch 29/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7050 - accuracy: 0.9764 - dice_coef: 0.7121\n","Epoch 00029: loss did not improve from -0.71945\n","15/15 [==============================] - 13s 895ms/step - loss: -0.7050 - accuracy: 0.9764 - dice_coef: 0.7121\n","Epoch 30/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7307 - accuracy: 0.9782 - dice_coef: 0.7372\n","Epoch 00030: loss improved from -0.71945 to -0.73075, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 992ms/step - loss: -0.7307 - accuracy: 0.9782 - dice_coef: 0.7372\n","Epoch 31/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7223 - accuracy: 0.9777 - dice_coef: 0.7122\n","Epoch 00031: loss did not improve from -0.73075\n","15/15 [==============================] - 14s 902ms/step - loss: -0.7223 - accuracy: 0.9777 - dice_coef: 0.7122\n","Epoch 32/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7201 - accuracy: 0.9782 - dice_coef: 0.7189\n","Epoch 00032: loss did not improve from -0.73075\n","15/15 [==============================] - 13s 856ms/step - loss: -0.7201 - accuracy: 0.9782 - dice_coef: 0.7189\n","Epoch 33/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7314 - accuracy: 0.9782 - dice_coef: 0.7342\n","Epoch 00033: loss improved from -0.73075 to -0.73143, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.7314 - accuracy: 0.9782 - dice_coef: 0.7342\n","Epoch 34/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7271 - accuracy: 0.9786 - dice_coef: 0.7366\n","Epoch 00034: loss did not improve from -0.73143\n","15/15 [==============================] - 13s 857ms/step - loss: -0.7271 - accuracy: 0.9786 - dice_coef: 0.7366\n","Epoch 35/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7263 - accuracy: 0.9781 - dice_coef: 0.7319\n","Epoch 00035: loss did not improve from -0.73143\n","15/15 [==============================] - 13s 894ms/step - loss: -0.7263 - accuracy: 0.9781 - dice_coef: 0.7319\n","Epoch 36/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7306 - accuracy: 0.9785 - dice_coef: 0.7271\n","Epoch 00036: loss did not improve from -0.73143\n","15/15 [==============================] - 13s 859ms/step - loss: -0.7306 - accuracy: 0.9785 - dice_coef: 0.7271\n","Epoch 37/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7301 - accuracy: 0.9786 - dice_coef: 0.7375\n","Epoch 00037: loss did not improve from -0.73143\n","15/15 [==============================] - 13s 893ms/step - loss: -0.7301 - accuracy: 0.9786 - dice_coef: 0.7375\n","Epoch 38/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7344 - accuracy: 0.9786 - dice_coef: 0.7300\n","Epoch 00038: loss improved from -0.73143 to -0.73443, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 983ms/step - loss: -0.7344 - accuracy: 0.9786 - dice_coef: 0.7300\n","Epoch 39/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7327 - accuracy: 0.9787 - dice_coef: 0.7242\n","Epoch 00039: loss did not improve from -0.73443\n","15/15 [==============================] - 13s 894ms/step - loss: -0.7327 - accuracy: 0.9787 - dice_coef: 0.7242\n","Epoch 40/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7336 - accuracy: 0.9790 - dice_coef: 0.7305\n","Epoch 00040: loss did not improve from -0.73443\n","15/15 [==============================] - 13s 865ms/step - loss: -0.7336 - accuracy: 0.9790 - dice_coef: 0.7305\n","Epoch 41/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7206 - accuracy: 0.9794 - dice_coef: 0.7091\n","Epoch 00041: loss did not improve from -0.73443\n","15/15 [==============================] - 14s 906ms/step - loss: -0.7206 - accuracy: 0.9794 - dice_coef: 0.7091\n","Epoch 42/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7178 - accuracy: 0.9777 - dice_coef: 0.7141\n","Epoch 00042: loss did not improve from -0.73443\n","15/15 [==============================] - 13s 854ms/step - loss: -0.7178 - accuracy: 0.9777 - dice_coef: 0.7141\n","Epoch 43/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7345 - accuracy: 0.9786 - dice_coef: 0.7341\n","Epoch 00043: loss improved from -0.73443 to -0.73447, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.7345 - accuracy: 0.9786 - dice_coef: 0.7341\n","Epoch 44/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7321 - accuracy: 0.9790 - dice_coef: 0.7231\n","Epoch 00044: loss did not improve from -0.73447\n","15/15 [==============================] - 13s 853ms/step - loss: -0.7321 - accuracy: 0.9790 - dice_coef: 0.7231\n","Epoch 45/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7387 - accuracy: 0.9787 - dice_coef: 0.7321\n","Epoch 00045: loss improved from -0.73447 to -0.73868, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 16s 1s/step - loss: -0.7387 - accuracy: 0.9787 - dice_coef: 0.7321\n","Epoch 46/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7310 - accuracy: 0.9791 - dice_coef: 0.7327\n","Epoch 00046: loss did not improve from -0.73868\n","15/15 [==============================] - 13s 855ms/step - loss: -0.7310 - accuracy: 0.9791 - dice_coef: 0.7327\n","Epoch 47/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7388 - accuracy: 0.9785 - dice_coef: 0.7437\n","Epoch 00047: loss improved from -0.73868 to -0.73880, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 1s/step - loss: -0.7388 - accuracy: 0.9785 - dice_coef: 0.7437\n","Epoch 48/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7421 - accuracy: 0.9793 - dice_coef: 0.7434\n","Epoch 00048: loss improved from -0.73880 to -0.74211, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 976ms/step - loss: -0.7421 - accuracy: 0.9793 - dice_coef: 0.7434\n","Epoch 49/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7380 - accuracy: 0.9801 - dice_coef: 0.7352\n","Epoch 00049: loss did not improve from -0.74211\n","15/15 [==============================] - 13s 892ms/step - loss: -0.7380 - accuracy: 0.9801 - dice_coef: 0.7352\n","Epoch 50/50\n","15/15 [==============================] - ETA: 0s - loss: -0.7501 - accuracy: 0.9791 - dice_coef: 0.7583\n","Epoch 00050: loss improved from -0.74211 to -0.75014, saving model to unet_cirrus.hdf5\n","15/15 [==============================] - 15s 980ms/step - loss: -0.7501 - accuracy: 0.9791 - dice_coef: 0.7583\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb564f14dd8>"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"id":"Xi0pMgABxbNz"},"source":["%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"09pVcBA8xbNz"},"source":["## C. Run the trained model on test images and save the outputs, and evaluate pixel-level segmentation performance "]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Qqv1bAEyxbN0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607820453219,"user_tz":300,"elapsed":3518,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"bd0ceda1-c661-4634-b680-807cf95c74b7"},"source":["#Step 1: Run model on test images and save the images\n","#number of test images\n","n_i=len(os.listdir('./Data/cirrus_3/test/Image/'))\n","#Call test generator\n","test_gen = testGenerator('./Data/cirrus_3/test/Image/')\n","#Return model outcome for each test image\n","results = model.predict_generator(test_gen,n_i,verbose=1)\n","#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!\n","saveResult('./Data/cirrus_3/test/Image/','./Data/cirrus_3/test/pred/',results)"],"execution_count":103,"outputs":[{"output_type":"stream","text":[" 2/48 [>.............................] - ETA: 1sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_predict_batch_end` time: 0.0383s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_predict_batch_end` time: 0.0383s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["48/48 [==============================] - 2s 41ms/step\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_168.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_165.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_157.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_151.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_159.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_160.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_164.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_156.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_163.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_166.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_150.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_161.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_162.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_155.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_181.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_189.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_199.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_194.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_200.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_174.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_192.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_193.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_179.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_180.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_188.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_175.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_169.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_178.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_171.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_185.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_195.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_184.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_173.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_190.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_191.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_177.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_172.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_196.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_170.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_186.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_182.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_183.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_176.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jdrkmsNjxbN0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607820481709,"user_tz":300,"elapsed":29177,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"5ac07ead-c441-4f16-ee27-c9addb754356"},"source":["#Step 2: Evaluate the predicted outcome\n","gt_path='./Data/cirrus_3/test/GT/'\n","evalResult(gt_path,results)"],"execution_count":104,"outputs":[{"output_type":"stream","text":["Precision= 0.4224409972518563 Recall= 0.3934644006739411 IoU= 0.2375191496978946 acc= 0.9930397669474283 F1= 0.35502934521514157\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7GG7teS-xbN0"},"source":["# Task 2: Vary kernels (dialated kernels), separable filters, loss function and rerun whole process. Does it improve test performance?\n","### Enter your results in the table below"]},{"cell_type":"markdown","metadata":{"id":"v8OqCFAcxbN1"},"source":["|U-net Parameters  (cirrus_3)          | Precision|Recall|IoU   |acc   |F1    |\n","|--------------------------------------|----------|------|------|------|-------|\n","|3x3 kernels, binary cross entropy     |0.24835538900162765|0.7491870690002833|0.2245623553621994|0.9848686854044596|0.341344742778606|\n","5x5 kernels, dilated kernels,dice_coef|0.4224409972518563|0.3934644006739411|0.2375191496978946|0.9930397669474283|0.35502934521514157|\n","5x5 kernels, dilated, depthwise separable kernels,dice_coef|0.4350959045761156|0.5033050235277282|0.2797362107966381|0.9930785497029623|0.4085315313745504|"]},{"cell_type":"markdown","metadata":{"id":"soh9uDkbxbN1"},"source":["## Select the best network parameters for semantic segmentation here and save the best unet_cirrus3.hdf5 model!"]},{"cell_type":"markdown","metadata":{"id":"XQDUqnOuxbN1"},"source":["# Task 3: Perform transfer learning with 'unet_cirrus3.hdf5' as base weights and retrain on the 'nidek1' data set (lesser epochs). Report the same table as above for the 'nidek1' test data."]},{"cell_type":"code","metadata":{"id":"saaBbutS6Cyb","executionInfo":{"status":"ok","timestamp":1607820539098,"user_tz":300,"elapsed":1114,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["# Load pretrained model.\n","pretrained_model = unet()\n","pretrained_model.load_weights('unet_cirrus.hdf5')"],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIihCP5qEBt6","executionInfo":{"status":"ok","timestamp":1607820539099,"user_tz":300,"elapsed":1001,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}}},"source":["# Setup the dataset.\n","PATH_RETRAIN='./Data/nidek_1/train/'\n","if not os.path.exists(PATH_RETRAIN+'aug'):\n","    os.makedirs(PATH_RETRAIN+'aug')\n","    \n","if not os.path.exists('./Data/nidek_1/test/'+'pred'):\n","    os.makedirs('./Data/nidek_1/test/'+'pred')    \n","data_gen = trainGenerator(10,PATH_RETRAIN,'Image','GT',data_gen_args, save_to_dir = PATH_RETRAIN+'aug')"],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tyGjpFMHaqi","executionInfo":{"status":"ok","timestamp":1607820679406,"user_tz":300,"elapsed":140902,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"293f6e38-29ec-405b-ec9c-59b183545df1"},"source":["# Retrain on nidek1.\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_nidek.hdf5', monitor='loss',verbose=1, save_best_only=True)\n","pretrained_model.fit(data_gen,steps_per_epoch=15,epochs=10,verbose=1, callbacks=[model_checkpoint, tensorboard_callback])"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Found 23 images belonging to 1 classes.\n","Found 23 images belonging to 1 classes.\n","Epoch 1/10\n"," 2/15 [===>..........................] - ETA: 9s - loss: -0.4855 - accuracy: 0.9857 - dice_coef: 0.4855WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2759s vs `on_train_batch_end` time: 0.6696s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2759s vs `on_train_batch_end` time: 0.6696s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["15/15 [==============================] - ETA: 0s - loss: -0.5019 - accuracy: 0.9877 - dice_coef: 0.5192\n","Epoch 00001: loss improved from inf to -0.50192, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 14s 904ms/step - loss: -0.5019 - accuracy: 0.9877 - dice_coef: 0.5192\n","Epoch 2/10\n","15/15 [==============================] - ETA: 0s - loss: -0.5537 - accuracy: 0.9884 - dice_coef: 0.5733\n","Epoch 00002: loss improved from -0.50192 to -0.55367, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 14s 946ms/step - loss: -0.5537 - accuracy: 0.9884 - dice_coef: 0.5733\n","Epoch 3/10\n","15/15 [==============================] - ETA: 0s - loss: -0.5638 - accuracy: 0.9893 - dice_coef: 0.5500\n","Epoch 00003: loss improved from -0.55367 to -0.56376, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 14s 929ms/step - loss: -0.5638 - accuracy: 0.9893 - dice_coef: 0.5500\n","Epoch 4/10\n","15/15 [==============================] - ETA: 0s - loss: -0.5476 - accuracy: 0.9884 - dice_coef: 0.5468\n","Epoch 00004: loss did not improve from -0.56376\n","15/15 [==============================] - 12s 794ms/step - loss: -0.5476 - accuracy: 0.9884 - dice_coef: 0.5468\n","Epoch 5/10\n","15/15 [==============================] - ETA: 0s - loss: -0.5847 - accuracy: 0.9877 - dice_coef: 0.5909\n","Epoch 00005: loss improved from -0.56376 to -0.58471, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 13s 891ms/step - loss: -0.5847 - accuracy: 0.9877 - dice_coef: 0.5909\n","Epoch 6/10\n","15/15 [==============================] - ETA: 0s - loss: -0.5891 - accuracy: 0.9884 - dice_coef: 0.5571\n","Epoch 00006: loss improved from -0.58471 to -0.58915, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 14s 927ms/step - loss: -0.5891 - accuracy: 0.9884 - dice_coef: 0.5571\n","Epoch 7/10\n","15/15 [==============================] - ETA: 0s - loss: -0.5918 - accuracy: 0.9892 - dice_coef: 0.5985\n","Epoch 00007: loss improved from -0.58915 to -0.59185, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 13s 899ms/step - loss: -0.5918 - accuracy: 0.9892 - dice_coef: 0.5985\n","Epoch 8/10\n","15/15 [==============================] - ETA: 0s - loss: -0.6094 - accuracy: 0.9893 - dice_coef: 0.6105\n","Epoch 00008: loss improved from -0.59185 to -0.60943, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 13s 898ms/step - loss: -0.6094 - accuracy: 0.9893 - dice_coef: 0.6105\n","Epoch 9/10\n","15/15 [==============================] - ETA: 0s - loss: -0.6433 - accuracy: 0.9900 - dice_coef: 0.6356\n","Epoch 00009: loss improved from -0.60943 to -0.64331, saving model to unet_nidek.hdf5\n","15/15 [==============================] - 14s 920ms/step - loss: -0.6433 - accuracy: 0.9900 - dice_coef: 0.6356\n","Epoch 10/10\n","15/15 [==============================] - ETA: 0s - loss: -0.6132 - accuracy: 0.9888 - dice_coef: 0.6062\n","Epoch 00010: loss did not improve from -0.64331\n","15/15 [==============================] - 12s 794ms/step - loss: -0.6132 - accuracy: 0.9888 - dice_coef: 0.6062\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb564786860>"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ajxhd9e2IQp-","executionInfo":{"status":"ok","timestamp":1607820681637,"user_tz":300,"elapsed":140423,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"b77d42a3-7777-44cf-a35e-bc4bca3d87be"},"source":["# Run model on test images and save the images\n","#number of test images\n","n_i=len(os.listdir('./Data/nidek_1/test/Image/'))\n","#Call test generator\n","test_gen = testGenerator('./Data/nidek_1/test/Image/')\n","#Return model outcome for each test image\n","results = pretrained_model.predict_generator(test_gen,n_i,verbose=1)\n","#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!\n","saveResult('./Data/nidek_1/test/Image/','./Data/nidek_1/test/pred/',results)"],"execution_count":108,"outputs":[{"output_type":"stream","text":["\r 1/30 [>.............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_predict_batch_end` time: 0.0445s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_predict_batch_end` time: 0.0445s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["30/30 [==============================] - 1s 36ms/step\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUu17VdtJGRQ","executionInfo":{"status":"ok","timestamp":1607820700296,"user_tz":300,"elapsed":18638,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"40ab173a-4c86-48b5-86f5-f5253aabfa4f"},"source":["# Evaluate the predicted outcome\n","gt_path='./Data/nidek_1/test/GT/'\n","evalResult(gt_path,results)"],"execution_count":109,"outputs":[{"output_type":"stream","text":["Precision= 0.29612102575566895 Recall= 0.9893657414466738 IoU= 0.2956455263405727 acc= 0.9429931640625 F1= 0.4398396351753104\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NP7lPvTVH6Yu"},"source":["|U-net Parameters  (nidek_1)          | Precision|Recall|IoU   |acc   |F1    |\n","|--------------------------------------|----------|------|------|------|-------|\n","|3x3 kernels, binary cross entropy     |nan|0.0|0.0|0.969653828938802|0.0|\n","5x5 kernels, dilated kernels,dice_coef|0.29612102575566895|0.9893657414466738|0.2956455263405727|0.9429931640625|0.4398396351753104|\n","5x5 kernels, dilated, depthwise separable kernels,dice_coef|nan|0.0|0.0|0.969653828938802|0.0|"]},{"cell_type":"markdown","metadata":{"id":"0fzyKEAcxbN2"},"source":["# Task 4: Report test data performance on Cirrus3 and Nidek1 for the following:\n","## A. Remove the BatchNormalization commands and add more batch normalizations after each conv2D layer for decoder networks.\n","## B. Activate dropout to test data (enable training=True) and create 2 cyst masks for each test image. Comment on the overlap between the cyst masks per image. What do you learn here?"]},{"cell_type":"markdown","metadata":{"id":"l5isZr9VZ3h0"},"source":["## 4.A.\n","\n","The best model was 5x5 kernels, dilated kernels, dice_coef. We retrain this model, adding and removing batch normalization and reporting results on cirrus3 and nidek_1.\n","\n","|U-net Parameters  (cirrus_3)          | Precision|Recall|IoU   |acc   |F1    |\n","|--------------------------------------|----------|------|------|------|-------|\n","|5x5 kernels, dilated kernels, dice_coef, no batch normalization|nan|0.0|0.0|0.9931999842325846|0.0|\n","|5x5 kernels, dilated kernels, dice_coef, extra batch normalization|nan|0.0|0.0|0.9931999842325846|0.0|\n","\n","|U-net Parameters  (nidek_1)          | Precision|Recall|IoU   |acc   |F1    |\n","|--------------------------------------|----------|------|------|------|-------|\n","|5x5 kernels, dilated kernels, dice_coef, no batch normalization|nan|0.0|0.0|0.9931999842325846|0.0|\n","|5x5 kernels, dilated kernels, dice_coef, extra batch normalization|nan|0.0|0.0|0.9931999842325846|0.0|\n","\n","We would have to retrain these models several times to make any real conclusions. It seems that we had poor random initializations, so we got useless predictions."]},{"cell_type":"markdown","metadata":{"id":"EBztnok3axn9"},"source":["## 4.B.\n","\n","We change the model to have training=True in dropout layers, and compare two sets of predictions."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqNEINiq6D8L","executionInfo":{"status":"ok","timestamp":1607821164916,"user_tz":300,"elapsed":3546,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"9b6c4293-3b4c-4704-9257-5013298a9db5"},"source":["# Run model on test images and save the images\n","#number of test images\n","n_i=len(os.listdir('./Data/nidek_1/test/Image/'))\n","#Call test generator\n","test_gen = testGenerator('./Data/nidek_1/test/Image/')\n","#Return model outcome for each test image\n","results = pretrained_model.predict_generator(test_gen,n_i,verbose=1)\n","#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!\n","if not os.path.exists('./Data/nidek_1/test/pred/dropout1/'):\n","  os.mkdir('./Data/nidek_1/test/pred/dropout1/')\n","if not os.path.exists('./Data/nidek_1/test/pred/dropout2/'):\n","  os.mkdir('./Data/nidek_1/test/pred/dropout2/')\n","saveResult('./Data/nidek_1/test/Image/','./Data/nidek_1/test/pred/dropout1/',results)\n","test_gen = testGenerator('./Data/nidek_1/test/Image/')\n","results = pretrained_model.predict_generator(test_gen,n_i,verbose=1)\n","saveResult('./Data/nidek_1/test/Image/','./Data/nidek_1/test/pred/dropout2/',results)"],"execution_count":121,"outputs":[{"output_type":"stream","text":["\r 1/30 [>.............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_predict_batch_end` time: 0.0452s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_predict_batch_end` time: 0.0452s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["30/30 [==============================] - 1s 37ms/step\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"],"name":"stderr"},{"output_type":"stream","text":["\r 1/30 [>.............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_predict_batch_end` time: 0.0259s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_predict_batch_end` time: 0.0259s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["30/30 [==============================] - 1s 35ms/step\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","/content/drive/MyDrive/Colab Notebooks/Week 7/unet_helper_functions.py:119: UserWarning: ./Data/nidek_1/test/pred/dropout2/bscan_77.jpg_predict.png is a low contrast image\n","  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n","WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"jNvUAKAUl-yJ","executionInfo":{"status":"ok","timestamp":1607821168615,"user_tz":300,"elapsed":316,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"cc9e3204-4871-48c2-dc6f-ad611980ee6a"},"source":["from IPython.display import Image\n","Image(filename='./Data/nidek_1/test/pred/dropout1/bscan_57.jpg_predict.png')"],"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAE+UlEQVR42u2d2XbbMAxENTz6/1+ePjRxLMvaARIg5z60p2lsE4OFIEXJ0ySEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghRGqQevQ8GD6PLSyje3jO7P8Tv3AY4SW3/Xyc352kwIYQwCAC8DgdehWAZ3O96wjANJG8/drkOY/ff2EgAWhnSveN0DgCoCcB1hWNXrlcYqf4mxIcKAXwZi6dy3XYCOBOq8c7K6N0RfCbCnFqZ43ZHdM08efP5XhpaMcc0vY/u/i764PdVV/2CNju7DiBq5HS0IaWNeA1x53Z1oCT1+YAXt+wn/izFW5BjHh5v6yCeGmxvRrMKQBPDu771rdZfxR6McRjCx87MPZqkPd3esILQJPfQiIB7ra1uC/fmVeV+j63iGpYBUC9PmDR9FxR4OssQCPz6zZCnF59bZt1HOqnwGe00yhzYdbBwNnnMFjLu46x1K0A9V/cVoAEl13g5O5X6GO1qWM3SsZshJbbl/QLA1pkR3EPMHiVEAatAbRdrnoXSPiNCG8HF2gSTN8+KPR+ACz1pUcC2AvAZecbfxosnv6v08pk2Q9oX+/aCWA59I/lVeA9QbjoyBs7Cr2kwMv7prmQ7LA0V73GUBHgkWblrhcirOfRpAYw8qweKAXQrQDoKgPuRADQzH6HsPKeBmnvdKaoAfCwHyFqQPP0ByILsLhqmWG+LJn8/7kpZHF4ojglf5reQneM+LmJgwpgXKV3S0HoEyJ0f2OMWQOMrzkhk+/f76WB3VsmEsBh3GVw+z0vjuZohpDM++YOUyc4eADYNUIcPAI4eApUsh9RBchrv40AmS8VlUT2I3ANSGv/43dlbvN3I4B9Jv1pAXYug3Miu4j/PQF4ytHMbv/9Isgu/L8twN55LJ0QkQCV4wCKAAnQSgDWjsjqn5cgAnz1frglBnrY+371h2iTAmgT7e+f+v8qM9rWAO/4xPefoJ7289PA9zkPUS/yStNxBDhQvCkA0GR8SPKB3LyT8+qHs3FIlLv2W8D29je+Z4jtS0JpGAAhSmKgVrjNlFDiBECbjaa56UAfPho/fQpEuLHKbksMl01HBBFKI7+h8YLToA8wWwciXQqgi+R/UgOQ+yvaLFLgmgIg2k30FYORyzfeeSY4+hTg816O1WPEGM9+pyd9bLwt49nvdNNUoiJZd6gMFwAN1gIdTaFplrxCCCGEECJSSxilJ9Q5wRBrAo4X84wiwFzP3wz5pOVSP97XuwItH1JZKtq/+R15LfdIUDUA3r9zZpUQ6DYFdrVoXRDqT4PcmAIa5cHs6uxvT8CEyxnzoNMgL/24qxTgTsnl1tzQhQDkyaVOkAuF8+EgLw7wcn5HjoA7X2XAs30dFn83O3Nxogjy+vmvMy5njItks3FwEoevw9u3b6J5GfB4rjCu/WbbE0fGj9K6sNPFKURDMJtlAC//YogaUB6VM67N2o2BXAckDnu1u194mOWMEHaj+yfdedu8IKctzxXBdXF71Moj+1HZNPFtKQAtDEdiAa4og0RaFLOYP9HVInMK7E2GK/NwZH+cMmi5JbZQgJ/zaNDqiNM+x9Z/5T76iQ3DcXBfMzuxfy8FcOzmDs79YiP2EXDhVm0WOLuv260AQ1E2iz+Hj4BvWdCfKjBr7vubBns3fb8RGsP6nT5g9JubhBBCCCGEEEIIIYTolX+MmzwrASfTOgAAAABJRU5ErkJggg==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":122}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"su07o395mgQ-","executionInfo":{"status":"ok","timestamp":1607821169629,"user_tz":300,"elapsed":302,"user":{"displayName":"Leonard Kosta","photoUrl":"https://lh6.googleusercontent.com/-XMthFflN3LY/AAAAAAAAAAI/AAAAAAAAAak/wE0K-Z7ahfo/s64/photo.jpg","userId":"02814793080107073701"}},"outputId":"da9dd44b-edcb-4ac2-9e1d-8d4481faeafe"},"source":["Image(filename='./Data/nidek_1/test/pred/dropout2/bscan_57.jpg_predict.png')"],"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAEoUlEQVR42u2d3XLrIAyEvQzv/8p7LnLaJk5MbEAgmf0u2uk0dS2xEsL8eNuEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCOIU3N49q4HZSaAGw3RXpDlHADas64GE5GvIBwkc/fn7Cog5otCUtbn/4HLBMN0irYI7iACymgIpejXdyAMeNY1LEgO/YCWzZicGYNXbNQRrdLEuGrAPQsZdQIeRW/rwiAcTNAdxmRb+H0SCr7429TMihG79DC6bF7Z/ogO/2lwYE3UJ3mAP21rDmjwz8kMa1N+tHeoY6SMP1zkuDPZZshw8ffjEAT3ZUDHmsbxD2DY+2fG/sgWQqd4eXG5EDdlmOtGlE0m0I/M7V0TRO6a4b/N8m70keMIqCdg93HQvg4KY8z7+NqAPQIabMsmMySAAfhqu08EAXL2Qb+7eNG9j1srDpHrOp9NmxN9h1pnSaAxgm+81/IOKjJNRj8RGdn2E5j5UUwNdqc8EQoMHEed62aBp4LjFiPBOk2RWxWAhYDLKSfYP6XtSePLfOPSpBuo6AGgcEXV48SQGdt7X0d34OJX+0TjIMVgAXDAE8fbexHwiVA9z3MEYOgOVV0TPBJjvT6bHBg48GDWTW3wEwz/1dJ1sNcgBg2weya3WVrW7SNPPDtQIMrWd3+wOsENlfG3372OXnBRBKAAb3m0OZ738wxHCCTYsHbDcH/BzlsGoSZFQBdFJA4PNs0toZoJMDIh9ohKUTwBbngYjjAxQY2v52BzD4kW0ojzzvHf9FBbBk3Y0OskuVYU8fMrV2AH1EwAwFLGB6fQjc6iTLCGMBeHMA7qSDtLgAWh1gcXO7FRBets5yYIOPXId2NBp8m+PFyc/FEX/DcBifz3AJmRZzdRPAsNXRZ19wUw7AZcd0FQCA2QrAgPB8zyDD1+FOrgPmrzueXQghqgNCrAK1cwD7uQST5ZBnNz8nR0OaGbhwkAtS+7231jyPr0AsB7Dddh9bb2AQzKf+6d+REJzqi2oFsNFXcLL3ykoBGHEYouNKENo4ufMAnoZ3rp4bmITA69kx73tIcEsF4K2gR4RY6Hh739/2w3snQbgzzt14nP4EMPaBiEd5pHtrTgghhBBCCOG5MmfAmSEp4PJzAHz5/SQVpJE698jAM0V9rsBPy8ShAwc8v22JdCKBNCv48ekTXCQESD85MRlayQgdQbIUPrfPCwk8PRh+rBLr/y6o0hnwBSEQcxzQvUivFbuzhZJHEu7d32NibKTjf0xWtybjVMM2SRAlx/iaIk0tYcwj6y47DNPm1gsbJi7awjYbZikCZ9q3pOinpU/X9k8hfgjw3A+u7S844OQd8rnHDHiyREMvUN9LeqqGq19x//LL/ScZxwH5bGvjOP5Db6TPJoI67EJxpxxQKJ/5V+HcOAlGTn3nHNC+o+31LACXcsDZSgcnyyR8zpr0ukAwD3IsQuYABDAgVhKM4oDfkv5l70NZ0giqFHyv+w7z1z5HMmKk5FonbS8vU0LYPJG+PwnAejnggs2I7qO0FbNgyOq214hm4W5QCCGEEEIIIYQQQgghxE35B8+oGjPnUZ44AAAAAElFTkSuQmCC\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"markdown","metadata":{"id":"7d1eKcfXnGQv"},"source":["# Conclusion\n","\n","Model architecture, like many hyperparameters, needs to be tuned with a light touch. Large perturbations will result in poor performance. Models should be tested iteratively, complexity being added slowly.\n","\n","If dropout is left in even at test time, predictions will be slightly noisy. The overlap between different such predictions on the same inputs shows where the model is most confident, as noise does not disturb the label.\n"]},{"cell_type":"markdown","metadata":{"id":"ERV8koHexbN2"},"source":[""]}]}